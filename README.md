# LORE-Applied-to-HRV-Data-for-OSA-Classification
Repositório do projeto FAPESP número 2024/04927-6

RESUMO

Neste trabalho estamos interessados em utilizar modelos de Inteligência Artificial Explicável (XAI) para interpretar decisões tomadas por modelos de Aprendizado de Máquina (AM), do tipo caixa-preta, na tarefa de classificação do grau de severidade da Apneia Obstrutiva do Sono (AOS) em pacientes. A Apneia Obstrutiva do Sono é um dos distúrbios do sono mais comuns, consistindo na ocorrência de cessação ou diminuição do fluxo aéreo durante o sono, sendo que o exame mais preciso e comum para diagnosticar distúrbios do sono é a Polissonografia que, apesar de sua eficácia, é um exame complexo e relativamente caro.
Em trabalhos anteriores já foram utilizados, de maneira bem sucedida, modelos de AM como Florestas Aleatórias (FA) e Perceptrons Multicamadas (MLP) para realizar a classificação do grau de severidade da AOS utilizando dados de Variabilidade da Frequência Cardíaca (VFC), Saturação de Oxigênio e dados antropométricos dos pacientes, obtidos a partir de 438 exames de Polissonografia, realizados entre 2015 e 2022 no Hospital das Clínicas vinculado à Faculdade de Medicina da USP  de Ribeirão Preto [SANTOS et al., 2024]. Os dados de VFC são obtidos através do exame de Eletrocardiograma, que se mostrou uma potencial alternativa ao exame de Polissonografia tido como padrão de ouro para o diagnóstico da doença.
Entretanto, os modelos usados na classificação, que são eficientes, muitas vezes não são interpretáveis, no sentido de que eles não conseguem nos fornecer significado ou explicações para as decisões tomadas em termos compreensíveis para os humanos. Já os modelos que são interpretáveis acabam sendo menos precisos, o que é indesejável em áreas como a Medicina, que exige tanto precisão quanto interpretabilidade. Além disso, com o avanço da IA, leis como o Regulamento Geral de Proteção de Dados da União Europeia surgiram para regular seu uso, incluindo o direito de explicação (artigo 22), que garante aos indivíduos o direito de entender decisões automatizadas que os afetam.
Neste projeto iremos aplicar o método LOcal Rule-based Explanations (LORE) e sua variação desenvolvida por nosso grupo de pesquisa LOcal Rule-based Explanations with fitness sharing (LOREfs) para explicar decisões de modelos de AM no problema Da classificação de severidade da Apneia do Sono por meio dos dados de VFC. Os algoritmos nos ajudam a entender quais atributos são mais importantes e exatamente como eles são utilizados pelos modelos de AM para a tomada de decisão, o que é de grande relevância para o entendimento de como a VFC é relacionada à Apneia do Sono.

ABSTRACT

In this work, we are interested in using Explainable Artificial Intelligence (XAI) models to interpret decisions made by black-box Machine Learning (ML) models in the task of classifying the severity level of Obstructive Sleep Apnea (OSA) in patients. Obstructive Sleep Apnea is one of the most common sleep disorders, characterized by the cessation or reduction of airflow during sleep. The most accurate and widely used exam for diagnosing sleep disorders is Polysomnography, which, despite its effectiveness, is a complex and relatively expensive procedure.

In previous studies, ML models such as Random Forests (RF) and Multilayer Perceptrons (MLP) have been successfully used to classify the severity of OSA using Heart Rate Variability (HRV) data, oxygen saturation, and anthropometric data from patients. These data were obtained from 438 Polysomnography exams conducted between 2015 and 2022 at the Hospital das Clínicas, affiliated with the Faculty of Medicine of the University of São Paulo in Ribeirão Preto [SANTOS et al., 2024]. HRV data are obtained through Electrocardiogram (ECG) exams, which have proven to be a potential alternative to Polysomnography, considered the gold standard for diagnosing the disease.

However, although the models used for classification are efficient, they are often not interpretable — meaning they do not provide meaningful or human-understandable explanations for the decisions they make. On the other hand, interpretable models tend to be less accurate, which is undesirable in fields such as medicine, where both accuracy and interpretability are crucial. Furthermore, with the advancement of AI, regulations such as the European Union’s General Data Protection Regulation (GDPR) have emerged to regulate its use, including the right to explanation (Article 22), which ensures individuals the right to understand automated decisions that affect them.

In this project, we will apply the LOcal Rule-based Explanations (LORE) method and its variation developed by our research group, LOcal Rule-based Explanations with fitness sharing (LOREfs), to explain decisions made by ML models in the task of classifying the severity of Sleep Apnea using HRV data. These algorithms help us understand which features are most important and precisely how they are used by ML models in decision-making, which is highly relevant for understanding how HRV is related to Sleep Apnea.

